```{r global_options, include=FALSE}
library(magrittr)
library(tidyr)
library(dplyr)
library(ggplot2)
library(cowplot)
library(reshape)
```
```{r}
PB1 <- merge_all(list(read.csv(file='H2N2PB1.tidy.csv', head=TRUE, sep='\t'), 
                      read.csv(file='H1N1PB1.tidy.csv', head=TRUE, sep='\t'), 
                      read.csv(file='H3N2PB1.tidy.csv', head=TRUE, sep='\t')), 
                 all.x=TRUE, all.y=TRUE)
codonvalues <- read.csv(file='codonvalues.csv', head=TRUE, sep='\t')
rtPB1 <- PB1 %>% left_join(select(codonvalues, codon, AIFNratiolib2, AnoIFNratiolib2, AIFNreadslib2, AnoIFNreadslib2, AIFNratiolib1, AnoIFNratiolib1, AIFNreadslib1, AnoIFNreadslib1, IFN2max, noIFN2min))
```

This whole thing has gotten pretty bloated!  Probably don't want to run it all at once!

*rtAI graphs based on older library*
Cutoffs are 0, 500, 1000 (removes 8 codons)
```{r}
rtPB1 %>% 
  filter(codon!='ATG', codon!='TGG', codon!='TAA', codon!='TAG', codon!='TGA') %>%
  group_by(sero, strain) %>%
  summarize(coryear=mean(coryear),
            score=(sum(numcodon*AIFNratiolib1/AnoIFNratiolib1))/sum(numcodon)) %>%
  ggplot(aes(x=coryear, y=score, color=sero)) + geom_point()

rtPB1 %>% 
  filter(codon!='ATG', codon!='TGG', codon!='TAA', codon!='TAG', codon!='TGA') %>% 
  filter(AIFNreadslib1 >= 500, AnoIFNreadslib1 >= 500) %>% 
  group_by(sero, strain) %>%
  summarize(coryear=mean(coryear),
            score=(sum(numcodon*AIFNratiolib1/AnoIFNratiolib1))/sum(numcodon)) %>%
  ggplot(aes(x=coryear, y=score, color=sero)) + geom_point()

rtPB1 %>% 
  filter(codon!='ATG', codon!='TGG', codon!='TAA', codon!='TAG', codon!='TGA') %>% 
  filter(AIFNreadslib1 >= 1000, AnoIFNreadslib1 >= 1000) %>% 
  group_by(sero, strain) %>%
  summarize(coryear=mean(coryear),
            score=(sum(numcodon*AIFNratiolib1/AnoIFNratiolib1))/sum(numcodon)) %>%
  ggplot(aes(x=coryear, y=score, color=sero)) + geom_point()
```

*rtAI graphs based on newer library*
Cutoffs for read # are 0, 1000 (removes one codon), 10000 (removes 8 codons).
```{r}
rtPB1 %>% group_by(sero, strain) %>% 
  filter(codon!='ATG', codon!='TGG', codon!='TAA', codon!='TAG', codon!='TGA') %>%
  summarize(coryear=mean(coryear),
            score=(sum(numcodon*AIFNratiolib2/AnoIFNratiolib2))/sum(numcodon)) %>%
  ggplot(aes(x=coryear, y=score, color=sero)) + geom_point()

rtPB1 %>% 
  filter(codon!='ATG', codon!='TGG', codon!='TAA', codon!='TAG', codon!='TGA') %>% 
  filter(AIFNreadslib2 >= 1000, AnoIFNreadslib2 >= 1000) %>% 
  group_by(sero, strain) %>%
  summarize(coryear=mean(coryear),
            score=(sum(numcodon*AIFNratiolib2/AnoIFNratiolib2))/sum(numcodon)) %>%
  ggplot(aes(x=coryear, y=score, color=sero)) + geom_point()

rtPB1 %>% 
  filter(codon!='ATG', codon!='TGG', codon!='TAA', codon!='TAG', codon!='TGA') %>% 
  filter(AIFNreadslib2 >= 10000, AnoIFNreadslib2 >= 10000) %>% 
  group_by(sero, strain) %>%
  summarize(coryear=mean(coryear),
            score=(sum(numcodon*AIFNratiolib2/AnoIFNratiolib2))/sum(numcodon)) %>%
  ggplot(aes(x=coryear, y=score, color=sero)) + geom_point()
```

OK.  gonna try calculating rtAI more like I do CAI.
Can't do geometric means with these values it seems like?  The difference between rtAIobs and rtAImax becomes so great that it just rounds off to 0?  I'm not totally sure, but rtAIobs/rtAImax found with the mean instead makes a reallllly small number (see below).  There is maybe a slight trend downwards in the graph below. That ain't great.
```{r}
rtPB1 %>% 
  filter(codon != 'ATG', codon!='TGG', codon!='TAA', codon!='TAG', codon!='TGA') %>% 
  filter(AIFNreadslib2 >= 0, AnoIFNreadslib2 >= 0) %>%
  group_by(sero, strain) %>% 
  mutate(cods = sum(numcodon)) %>% 
  summarize(coryear=mean(coryear),
            score=((sum((AIFNratiolib2/AnoIFNratiolib2) * numcodon))*mean(1/cods))/((sum((IFN2max/noIFN2min) * numcodon)))*mean(1/cods)) %>%
  ggplot(aes(x=coryear, y=score, color=sero)) + geom_point() + ylim(2.7e-07, 3.1e-07)
```


It this tRNA stuff a red herring?  Gonna try this a few more ways:
Here I'm finding geometric mean instead of average (not putzing around with any rtAImax stuff)
```{r}
rtPB1 %>% group_by(sero, strain) %>% 
  filter(codon!='ATG', codon!='TGG', codon!='TAA', codon!='TAG', codon!='TGA') %>% 
  filter(AIFNreadslib2 >= 0, AnoIFNreadslib2 >= 0) %>%
  summarize(coryear=mean(coryear),
            score=(prod(numcodon**(AIFNratiolib2/AnoIFNratiolib2)))**(1/sum(numcodon))) %>% 
  filter(score > 0) %>%
  ggplot(aes(x=coryear, y=score, color=sero)) + geom_point()
```
This doesn't work cause values are getting rounded to 0 again, I think.  I should try to find a different way to do this stuff so there's no rounding problems?

Oh, yes, Dr. Wilke recommended I take the log of the ratio.  I'll try that out:
```{r}
rtPB1 %>% group_by(sero, strain) %>% 
  filter(codon!='ATG', codon!='TGG', codon!='TAA', codon!='TAG', codon!='TGA') %>% 
  filter(AIFNreadslib2 >= 0, AnoIFNreadslib2 >= 0) %>%
  summarize(coryear=mean(coryear),
            score=(sum(numcodon*log(AIFNratiolib2/AnoIFNratiolib2)))/sum(numcodon)) %>%
  ggplot(aes(x=coryear, y=score, color=sero)) + geom_point()
```

Doesn't seem to do much!

Maybe I'm going about using the maxs and mins wrong.  Let's try this another way:
```{r}
rtPB1 %>% 
  filter(codon!='ATG', codon!='TGG', codon!='TAA', codon!='TAG', codon!='TGA') %>% 
  filter(AIFNreadslib2 >= 1000, AnoIFNreadslib2 >= 1000) %>% 
  group_by(sero, strain) %>%
  summarize(coryear=mean(coryear),
            score=(sum(numcodon*(AIFNratiolib2/IFN2max)/(AnoIFNratiolib2/noIFN2min)))/sum(numcodon)) %>%
  ggplot(aes(x=coryear, y=score, color=sero)) + geom_point() + ylim(.45, .475)
```

Now H3N2 has maybe no trend...
Oh wait, what if I remove every set of codons that only have one tRNA that services them, instead of just every amino acid with only one codon?
```{r}
rtPB1 %>% group_by(sero, strain) %>% 
  filter(AIFNratiolib2 != 0.5, AIFNratiolib2 != 1) %>% 
  filter(AIFNreadslib2 >= 0, AnoIFNreadslib2 >= 0) %>% 
  summarize(coryear=mean(coryear),
            score=(sum(numcodon*AIFNratiolib2/AnoIFNratiolib2))/sum(numcodon)) %>%
  ggplot(aes(x=coryear, y=score, color=sero)) + geom_point()
```
Doesn't really change anything, although this probably is a better way to filter which codons I want to use overall...

__Maybe I just need to get a better library sequenced__
When I filter by 10,000 reads, the whole thing looks pretty good, but that's removing 8 codons from the analysis.  Those're low frequency tRNAs and it might just be that my library prep just didn't get a representative sample from them.